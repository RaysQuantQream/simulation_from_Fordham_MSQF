{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus HW6: 2 Dimensional Gaussian Copula and Integration\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "import scipy.special as special\n",
    "import numpy.linalg as linalg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=47693\n",
    "gen=np.random.default_rng(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "#### Black-Scholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=1e-12\n",
    "\n",
    "def bs_price_fwd(isCall, K, T, F, sigma):\n",
    "    \"\"\" Black's pricing formula\n",
    "    \n",
    "    European option  forward price as a function of\n",
    "    the asset's forward.\n",
    "    \n",
    "    :param isCall: True for calls , False for Puts\n",
    "    :type isCall: Boolean\n",
    "    :param K: option strike\n",
    "    :param T: option expiry in years\n",
    "    :param F: forward of the options underlying asset\n",
    "    :param sigma: underlying's  volatility\n",
    "    :return: option's forward price\n",
    "    \"\"\"\n",
    "    ds=np.maximum(0.000001,sigma*np.sqrt(T))\n",
    "    dsig=0.5*ds*ds\n",
    "    d2=(np.log(F/np.maximum(K,epsilon))-dsig)/ds\n",
    "    d1=d2+ds\n",
    "    if isCall:\n",
    "        opt= F*special.ndtr(d1) - K*special.ndtr(d2)\n",
    "    else:\n",
    "        opt= K*special.ndtr(-d2) - F*special.ndtr(-d1)\n",
    "    return opt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVI Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVICurve:\n",
    "    def __init__(self,T,F,vol_ATM,b,rho,m,sigma):\n",
    "        self.T=T\n",
    "        self.F=F\n",
    "        self.a=vol_ATM**2*T-b*(-rho*m+np.sqrt(m**2+sigma**2)) \n",
    "        self.b=b\n",
    "        self.rho=rho\n",
    "        self.m=m\n",
    "        self.sigma=sigma        \n",
    "    def __call__(self,K):\n",
    "        k=np.log(K/self.F)\n",
    "        var=self.a + self.b*(self.rho*(k-self.m)+np.sqrt((k-self.m)**2+self.sigma**2))\n",
    "        return np.sqrt(var/self.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RiskNeutral Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskNeutral:\n",
    "    def __init__(self,T,F,vol):\n",
    "        self.T=T\n",
    "        self.F=F\n",
    "        self.vol=vol\n",
    "    def cdf(self,K,dk=0.001):\n",
    "        dK=K*dk\n",
    "        K0=K-dK\n",
    "        sig0=self.vol(K0)\n",
    "        p0=bs_price_fwd(False,K0,self.T,self.F,sig0)\n",
    "        K1=K+dK\n",
    "        sig1=self.vol(K1)\n",
    "        p1=bs_price_fwd(False,K1,self.T,self.F,sig1)\n",
    "        return  (p1-p0)/dK/2.0\n",
    "    def pdf(self,K,dk=0.001):\n",
    "        dK=K*dk\n",
    "        return (self.cdf(K)-self.cdf(K-dK))/dK       \n",
    "    def ppf(self,u,tol=1e-4,max_iter=21): # inverse cdf\n",
    "        T=self.T\n",
    "        F=self.F\n",
    "        sigma=self.vol(F)\n",
    "        var=sigma**2*T\n",
    "        std=np.sqrt(var)\n",
    "        S=np.empty_like(u.ravel())\n",
    "        \n",
    "        S0=F*np.exp(-15*std)\n",
    "        cdf0=self.cdf(S0)\n",
    "        pdf0=self.pdf(S0)\n",
    "        u1=u.ravel() #linearize into one long vector\n",
    "        idx=u1.argsort() # we will visit them in increasing order\n",
    "        for i1 in range(len(idx)):\n",
    "            U=u1[idx[i1]]\n",
    "            # solve equation  \n",
    "            #    cdf(S)=u\n",
    "            # using brent's method\n",
    "            iter=0\n",
    "            while np.abs(cdf0-U)/cdf0>tol:\n",
    "                S1=S0+(U-cdf0)/pdf0\n",
    "                cdf1=self.cdf(S1)\n",
    "                pdf0=(cdf1-cdf0)/(S1-S0)\n",
    "                cdf0=cdf1\n",
    "                S0=S1\n",
    "                iter+=1\n",
    "                if (iter>=max_iter):\n",
    "                    break\n",
    "            S[idx[i1]]=S0\n",
    "                    \n",
    "        return S.reshape(u.shape)\n",
    "    def rvs(self,gen,size,tol=1e-4,max_iter=21):\n",
    "        u=gen.uniform(size=size)\n",
    "        return self.ppf(u,tol,max_iter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianCopula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianCopula:\n",
    "    def __init__(self,rho):\n",
    "        self.rho=rho\n",
    "    def generate(self,N,gen):\n",
    "        D=len(self.rho)\n",
    "        Z=stats.multivariate_normal(np.zeros(D),self.rho,seed=gen,allow_singular=True).rvs(size=N)\n",
    "        U=stats.norm.cdf(Z)\n",
    "        return U"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Copula Correlated Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distribution(dists,copula,N,gen):\n",
    "    U=copula.generate(N,gen) # correlated U(0,1)\n",
    "    Ss=[]\n",
    "    for i1,dist in enumerate(dists):\n",
    "        S=dist.ppf(U[:,i1]) # inverse cdf\n",
    "        Ss.append(S)\n",
    "    return np.stack(Ss,axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Dimensional Mid Point Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mid_point_rule_2d(func, a1, b1, a2,b2, N):\n",
    "    dx1=(b1-a1)/(N+1)\n",
    "    dx2=(b2-a2)/(N+1)\n",
    "    x1=np.linspace(a1+dx1/2,b1-dx1/2,N)\n",
    "    x2=np.linspace(a2+dx2/2,b2-dx2/2,N)   \n",
    "    y=func(x1[:,np.newaxis],x2[np.newaxis,:]) \n",
    "    I= np.sum(y)  \n",
    "    return dx1*dx2*I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytic Worst of 2 Asset Call/Put Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def N2(z1,z2,corr):\n",
    "    return stats.multivariate_normal(mean=[0,0], cov=[[1,corr],[corr,1]]).cdf([z1,z2])\n",
    "\n",
    "def M(T,K,F1,F2,sig1,sig2,rho):  \n",
    "    var1=0.5*sig1**2*T\n",
    "    var2=0.5*sig2**2*T\n",
    "    std1=sig1*np.sqrt(T)\n",
    "    std2=sig2*np.sqrt(T)\n",
    "    gamma1=(np.log(F1/K)-var1)/std1\n",
    "    gamma2=(np.log(F2/K)-var2)/std2\n",
    "    sigma_square=(sig1**2)+(sig2**2)-2*rho*sig1*sig2\n",
    "    sigma=np.sqrt(sigma_square)\n",
    "    var=0.5*sigma_square*T\n",
    "    std=sigma*np.sqrt(T)\n",
    "\n",
    "    alpha1=gamma1+std1\n",
    "    beta1=(np.log(F2/F1)-var)/std\n",
    "    theta1=(rho*sig2-sig1)/sigma\n",
    "\n",
    "    alpha2=gamma2+std2\n",
    "    beta2=(np.log(F1/F2)-var)/std\n",
    "    theta2=(rho*sig1-sig2)/sigma\n",
    "    \n",
    "    alpha3=gamma1\n",
    "    beta3=gamma2\n",
    "    theta3=rho\n",
    "    \n",
    "\n",
    "    N2_cdf_1=N2(alpha1,beta1,theta1)\n",
    "    N2_cdf_2=N2(alpha2,beta2,theta2)\n",
    "    N2_cdf_K=N2(alpha3,beta3,theta3)\n",
    "   \n",
    "    M_cdf=(F1*N2_cdf_1)+(F2*N2_cdf_2)-(K*N2_cdf_K)\n",
    "    \n",
    "    return M_cdf\n",
    "\n",
    "# analytic worst of two option\n",
    "def worst_option_fwd(is_call,T,K,F1,F2,sig1,sig2,rho):  \n",
    "    if is_call==True:\n",
    "        payoff=M(T,K, F1,F2,sig1,sig2,rho)\n",
    "    else:\n",
    "        payoff=K-M(T,0.00001,F2,F1,sig2,sig1,rho)+M(T,K,F2,F1,sig2,sig1,rho)        \n",
    "    return payoff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Cholesky Decomposition in Two Dimensions\n",
    "\n",
    "#### Problem 1.1\n",
    "using [`numpy.linalg.cholesky`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.cholesky.html)\n",
    "compute the cholesky decomposition $L$ of two assets with correlation $\\rho=70\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.7],\n",
       "       [0.7, 1. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=np.array([[1,rho],[rho,1]])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [0.7       , 0.71414284]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L=linalg.cholesky(corr)\n",
    "L"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2\n",
    "\n",
    "Check that the cholesky decomposition $L$ is given by:\n",
    "\n",
    "$$\n",
    "    L = \\begin{pmatrix}\n",
    "            1 & 0 \\\\\n",
    "            \\rho & \\sqrt{1-\\rho^2}\n",
    "        \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "[NOTE] \n",
    "\n",
    "This implies that, given independent $\\mathcal{N}(0,1)$ random variables $z_1$ and $z_2$ we can generate\n",
    "\\begin{align}\n",
    "    w_1 &= z_1 \\\\\n",
    "    w_2 &= \\rho z_1 + \\sqrt{1-\\rho^2} z_2\n",
    "\\end{align}\n",
    "Where $w_1$ and $w_2$ are again Gaussain $\\mathcal{N}(0,1)$ but with correlation $\\rho$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714142842854285"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1-rho**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: 2 Dimensional Gaussian Copula Transform:\n",
    "\n",
    "We can transform two undependent $U(0,1)$ random variables $u_1$, $u_2$ into two $U(0,1)$ correlated variables $v_1, v_2$ using the Gaussian copula with the function:\n",
    "$$\n",
    "    (v_1,v_2) = C_T(u_1,u_2;\\rho)\n",
    "$$\n",
    "that is implemented with following algorithm:\n",
    "\\begin{align*}\n",
    "    z_1&=\\text{N}^{-1}(u_1) & z_1,z_2 \\ \\ \\text{are independent Gaussians}\\\\\n",
    "    z_2&=\\text{N}^{-1}(u_2) &\\\\\n",
    "    w_1 &= z_1  & w_1,w_2 \\ \\ \\text{are correlated Gaussians}\\\\\n",
    "    w_2 &= \\rho z_1 + \\sqrt{1-\\rho^2} z_2 \\\\\n",
    "    v_1 &= \\text{N}(w_1) & v_1, v_2\\ \\ \\text{are correlated U}(0,1) \\\\\n",
    "    v_2 &= \\text{N}(w_2)\n",
    "\\end{align*}\n",
    "\n",
    "where $N(z)$ is the CDF for the standard Gaussian $\\mathcal{N}(0,1)$ distribution and $N^{-1}(u)$ is its  inverse.\n",
    "\n",
    "Write function `gaussian_copula_transform` implementing the transformation above:\n",
    "\n",
    "[HINT]  In `scipy` the Gaussian  CDF $N(z)$ is implemented by function [`scipy.special.ndtr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy_special.ndtr.html), and its inverse $N^{-1}(z)$ is implemented by [`scipy.special.ndtri`](https://docs.scipy.org/doc/scipy/reference/generated/scipy_special.ndtri.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_copula_transform(u1,u2,rho):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_copula_transform(u1,u2,rho):\n",
    "    z1=special.ndtri(u1)\n",
    "    z2=special.ndtri(u2)\n",
    "    w1=z1\n",
    "    w2=rho*z1+np.sqrt(1-rho**2)*z2\n",
    "    x1=u1\n",
    "    x2=special.ndtr(w2)\n",
    "    return x1,x2 # correlated U(1,0) marginals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Analytic Wost Of Call Price\n",
    "\n",
    "Compute the **analytic price** of a **Worst of 2 assets** call option with\n",
    "1. Expiry $T=1$ year.\n",
    "2. Strike $K=0.8$\n",
    "using the function   [worst_option_fwd](#analytic-worst-of-2-asset-callput-price) that is implemented above in the [Code](#code) section.\n",
    "\n",
    "Given that the assets have **correlation** $\\rho=70\\%$\n",
    "and the following characteristics:\n",
    "1. **Asset 1**: Forward $F=1$ and volatility $\\sigma_{\\text{ATM},1}=19\\%$\n",
    "2. **Asset 2**: Forward $F=1$ and volatility $\\sigma_{\\text{ATM},1}=25\\%$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=1\n",
    "is_call=True\n",
    "K=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1=1\n",
    "sigma_ATM=0.19\n",
    "F2=1\n",
    "sigma_ATM2=0.25\n",
    "\n",
    "rho=0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15491236163669841"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I0=worst_option_fwd(is_call,T,K,1,1,sigma_ATM,sigma_ATM2,rho)\n",
    "I0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Log Normal Price\n",
    "\n",
    "### Problem 4.1\n",
    "Generate two [`scipy.stats.lognorm`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html) distributions based on the market date of \n",
    "Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1=sigma_ATM**2*T\n",
    "dist1_ln=stats.lognorm(s=np.sqrt(var1),scale=F1*np.exp(-0.5*var1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2=sigma_ATM2**2*T\n",
    "f2=1\n",
    "dist2_ln=stats.lognorm(s=np.sqrt(var2),scale=F2*np.exp(-0.5*var2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2:\n",
    "\n",
    "Write the worst of two options payout\n",
    "$$\n",
    "    \\text{payout}_{W}(S1,S2,K) = \\max ( \\min(S1,S2)-K,0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worstof_call_payoff(S1,S2,K):\n",
    "    W=np.minimum(S1,S2)  # worst of price\n",
    "    return np.maximum(W-K,0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.3:\n",
    "\n",
    "Write the **Gaussian copula** transformed payout using the following algorithm:\n",
    "\\begin{align*}\n",
    "    v_1,v_2&=C_T(u_1,u_2,\\rho) \\\\\n",
    "    S_1 &= CDF_1^{-1}(v_1) \\\\\n",
    "    S_2 &= CDF_2^{-1}(v_2) \\\\\n",
    "    \\text{payout}&=\\text{payout}_{W}(S1,S2,K)\n",
    "\\end{align*}\n",
    "where:\n",
    "1. $C_T(u_1,u_2,\\rho)$ is the two dimensional Gaussian copula transformation `gaussian_copula_transform` implemented in Problem 2.\n",
    "2. $CDF_1^{-1}$ is the inverse CDF of asset 1.\n",
    "3. $CDF_2^{-1}$ is the inverse CDF of asset 2.\n",
    "4. $\\text{payout}_{W}(S1,S2,K)$ is the worst of two assets call payout implemented in Problem 4.2\n",
    "\n",
    "[HINT] For `scipy.stats` distributions the inverse CDF is called `ppf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worstof_option_payoff_transformed(u1,u2,K,dist1,dist2,rho):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worstof_option_payoff_transformed(u1,u2,K,dist1,dist2,rho):\n",
    "    v1,v2=gaussian_copula_transform(u1,u2,rho)\n",
    "    S1=dist1.ppf(v1)\n",
    "    S2=dist2.ppf(v2)\n",
    "    return worstof_call_payoff(S1,S2,K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.4:\n",
    "\n",
    "Use the [mid_point_rule_2d](#two-dimensional-mid-point-rule) to integrate the worst of two call transformed payout you implemented in Problem 4.3.\n",
    "\n",
    "Compare the result to the Analytic Result.\n",
    "\n",
    "[HINTS] \n",
    "1. The integration limits are $(0,1)$ for both $u_1$ and $u_2$.\n",
    "2. Choose a number of points that you think is sufficient to provide $\\approx 1\\%$ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15379132613338017"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_g=300\n",
    "I_g=mid_point_rule_2d(lambda u1,u2: worstof_option_payoff_transformed(u1,u2,K,dist1_ln,dist2_ln,rho),0,1,0,1,N_g)\n",
    "I_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007236578743453031"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(I_g-I0)/I0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Risk Neutral distribution\n",
    "\n",
    "From option market data we calibrate volatility curve for $T=1$ year two both assets.\n",
    "\n",
    "Both assets have unit forwards ($F_1=1$ and $F_2=1$) and the following SVI curve parameters:\n",
    "1. **Asset 1**:\n",
    "    1. $\\sigma_{ATM}$=19%\n",
    "    1. $b$=0.13\n",
    "    2. $\\rho$ = -0.734\n",
    "    3. $m$=0.128\n",
    "    4. $\\sigma$=0.118\n",
    "1. **Asset 2**:\n",
    "    1. $\\sigma_{ATM}$=25%\n",
    "    1. $b$=0.07\n",
    "    2. $\\rho$ = -0.85\n",
    "    3. $m$=0.08\n",
    "    4. $\\sigma$=0.13\n",
    "\n",
    "Define the risk neutral distributions of both assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=1\n",
    "F=1\n",
    "sigma_ATM=0.19\n",
    "b=0.13\n",
    "rho_svi=-0.734\n",
    "m=0.128\n",
    "sigma=0.118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2=1\n",
    "sigma_ATM2=0.25\n",
    "b2=0.07\n",
    "rho2_svi=-0.85\n",
    "m2=0.08\n",
    "sigma2=0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1=SVICurve(T,F,sigma_ATM,b,rho_svi,m,sigma)\n",
    "dist1=RiskNeutral(T,F,vol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol2=SVICurve(T,F2,sigma_ATM2,b2,rho2_svi,m2,sigma2)\n",
    "dist2=RiskNeutral(T,F2,vol2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.2\n",
    "\n",
    "Price the worst of call on the works of the two assets (by integration, as you did in Problem 4) using the risk neutral distributions defined in Problem 5.1 and a correlation $\\rho=70\\%$ between the two assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17293261104589433"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I=mid_point_rule_2d(lambda u1,u2: worstof_option_payoff_transformed(u1,u2,K,dist1,dist2,rho),0,1,0,1,300)\n",
    "I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.3\n",
    "\n",
    "We have no analytic formula to check the accuracy of the price computed in Problem 5.2\n",
    "\n",
    "Use Monte Carlo to generate $N=10,000$ samples of the risk neutral distribution of the two assets, correlated with the Gaussian Copula.\n",
    "\n",
    "Compare the prices you obtained to those of problem 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10_000\n",
    "copula=GaussianCopula(corr)\n",
    "S=generate_distribution([dist1,dist2],copula,N,gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1744546010131932, 0.0014293983664954068)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pay=worstof_call_payoff(S[:,0],S[:,1],K)\n",
    "I_mc=pay.mean()\n",
    "dI=pay.std()/np.sqrt(N)\n",
    "I_mc,dI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0647766241894414"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the two prices are comparable given the MC standard deviation\n",
    "(I-I_mc)/dI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6677d9b047f4c173977b2b074d0913ef1a6f70e2c3329275c5f9e5084df3020"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
